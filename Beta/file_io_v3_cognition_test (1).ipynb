{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09eaab45-dafd-476e-93e4-a27a5628ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt') # Already up-to-date\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a4ad21db-61f2-48e8-9d88-83877546ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Cars', 'are', 'very', 'red']\n",
      "\n",
      "<class 'list'>\n",
      "[('Cars', 'NNS'), ('are', 'VBP'), ('very', 'RB'), ('red', 'JJ')]\n",
      "\n",
      "\n",
      "[('Cars', 'NOUN'), ('are', 'VERB'), ('very', 'ADV'), ('red', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Default nltk.pos_tag uses the penn treebank\n",
    "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "# Going to use the universal tagger for this part of the project\n",
    "# https://www.nltk.org/_modules/nltk/tag/mapping.html\n",
    "\n",
    "# NLTK PoS Tagging Examples\n",
    "# https://pythonexamples.org/nltk-pos-tagging/\n",
    "\n",
    "# If Date is valid extract text\n",
    "text = \"Cars are very red\"\n",
    "\n",
    "tokens = nltk.word_tokenize(text) # Create a list of tokens\n",
    "print(type(tokens))\n",
    "print(tokens)\n",
    "print()\n",
    "\n",
    "\n",
    "tokens_tagged = nltk.pos_tag(tokens)\n",
    "print(type(tokens_tagged))\n",
    "print(tokens_tagged)\n",
    "print()\n",
    "print()\n",
    "\n",
    "tokens_tagged = nltk.pos_tag(tokens, tagset='universal')\n",
    "print(tokens_tagged)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd9bf449-2933-44d8-bc34-121ad3e6d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NOUN', 'VERB', 'ADV'], ['NOUN', 'VERB', 'ADP'], ['NOUN', 'VERB', 'ADV', 'ADJ'], ['NOUN', 'VERB', 'NOUN', 'ADP'], ['NOUN', 'VERB', 'ADJ'], ['NOUN', 'VERB', 'ADJ', 'NOUN']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Five Sentence Patter Rules\n",
    "# Assumption, all sentences are made up of\n",
    "# a subject and a predicate.\n",
    "\n",
    "sub_verb_mods_one = ['NOUN', 'VERB', 'ADV']\n",
    "sub_verb_mods_two = ['NOUN', 'VERB', 'ADP']\n",
    "\n",
    "sub_verb_do_mods_one = ['NOUN', 'VERB', 'ADV', 'ADJ']\n",
    "sub_verb_do_mods_two = ['NOUN', 'VERB', 'NOUN', 'ADP']\n",
    "\n",
    "# sub_verb_io_do = ['NOUN', 'VERB', 'NOUN', 'ADV']\n",
    "\n",
    "sub_link_verb_pred_adje = ['NOUN', 'VERB', 'ADJ']\n",
    "\n",
    "sub_link_verb_pred_noun = ['NOUN', 'VERB', 'ADJ', 'NOUN']\n",
    "\n",
    "super_list = []\n",
    "super_list.append(sub_verb_mods_one)\n",
    "super_list.append(sub_verb_mods_two)\n",
    "super_list.append(sub_verb_do_mods_one)\n",
    "super_list.append(sub_verb_do_mods_two)\n",
    "super_list.append(sub_link_verb_pred_adje)\n",
    "super_list.append(sub_link_verb_pred_noun)\n",
    "\n",
    "\n",
    "#super_list = [['NOUN', 'VERB', 'ADV'], ['NOUN', 'VERB', 'ADP'], ['NOUN', 'VERB', 'ADV', 'ADJ'], ['NOUN', 'VERB', 'NOUN', 'ADP'], ['NOUN', 'VERB', 'ADJ'], ['NOUN', 'VERB', 'ADJ', 'NOUN']]\n",
    "#print(sub_verb_mods_one)\n",
    "#print(sub_verb_mods_two)\n",
    "#print(sub_verb_do_mods_one)\n",
    "#print(sub_verb_do_mods_two)\n",
    "#print(sub_link_verb_pred_adje)\n",
    "#print(sub_link_verb_pred_noun)\n",
    "print(super_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8499ea1a-ba18-4747-a3af-467a8ca852bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['NOUN', 'VERB', 'ADV', 'ADJ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(len(tokens_tagged))\n",
    "#print(type(tokens_tagged))\n",
    "print()\n",
    "\n",
    "pos_tokens = ''\n",
    "\n",
    "# Loop the dict of tokens\n",
    "for token in tokens_tagged:\n",
    "    pos_tokens += token[1] + ' '\n",
    "\n",
    "#print(pos_tokens)\n",
    "\n",
    "sentence = str(pos_tokens)#'Whoever is happy will make others happy too'\n",
    "trigrams = ngrams(sentence.split(), 3)\n",
    "#print(type(list(trigrams)))\n",
    "quadgrams = ngrams(sentence.split(), 4)\n",
    "#print(type(list(quadgrams)))\n",
    "\n",
    "trigram_list = []\n",
    "for item in trigrams:\n",
    "    trigram_list.append(item[0])\n",
    "    trigram_list.append(item[1])\n",
    "    trigram_list.append(item[2])\n",
    "#print(trigram_list)\n",
    "\n",
    "quadgram_list = []\n",
    "for item in quadgrams:\n",
    "    quadgram_list.append(item[0])\n",
    "    quadgram_list.append(item[1])\n",
    "    quadgram_list.append(item[2])\n",
    "    quadgram_list.append(item[3])\n",
    "print(quadgram_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9800f5e6-c6af-43d6-9565-2bf66f734e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if trigram_list in super_list or quadgram_list in super_list:\n",
    "    print('match')\n",
    "elif quadgram_list in super_list:\n",
    "    print('match quad')\n",
    "else:\n",
    "    print('no grammar')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee71aa4-966f-4944-afdb-5b626ce0bbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
